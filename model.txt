Download the desired quantized Llama2-7B-Chat model from https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML/tree/main

Run the command to download the model "wget https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML/resolve/main/llama-2-7b-chat.ggmlv3.q8_0.bin"
